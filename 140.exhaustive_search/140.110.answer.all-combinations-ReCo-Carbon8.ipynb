{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    import progressbar\n",
    "    g_have_progressbar = True\n",
    "except:\n",
    "    g_have_progressbar = False\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "pd.set_option(\"display.max_columns\", 60)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NAME = \"ReCo\"  # ReCo or Carbon8\n",
    "REGRESSION_MODEL = \"Linear\"  # Linear, Ridge, RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA = {\"outputdir\": \"image_executed\", \"prefix\": \"exhaustivesearch\", \n",
    "              \"dataname\":DATA_NAME, \"regtype\":REGRESSION_MODEL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_name=\"ReCo\"):\n",
    "    \"\"\"load data.\n",
    "\n",
    "    Args:\n",
    "        data_name (str, optional): データ名 \"ReCo\" or \"Carbon8\". Defaults to \"ReCo\".\n",
    "\n",
    "    Raises:\n",
    "        ValueError: unknown data_name\n",
    "\n",
    "    Returns:\n",
    "        tuple containing\n",
    "\n",
    "        - pd.DataFrame: データ\n",
    "        - list[str]: 説明変数名リスト\n",
    "        - str: 目的変数\n",
    "    \"\"\"\n",
    "    if data_name == \"ReCo\":\n",
    "        df = pd.read_csv(\"../data/TC_ReCo_detail_descriptor.csv\")\n",
    "        descriptor_names = ['C_R', 'C_T', 'vol_per_atom', 'Z', 'f4', 'd5', 'L4f', 'S4f', 'J4f',\n",
    "                            '(g-1)J4f', '(2-g)J4f']\n",
    "        target_name = 'Tc'\n",
    "    elif data_name == \"Carbon8\":\n",
    "        df = pd.read_csv(\"../data_calculated/Carbon8_cell_descriptor_Etot.csv\")\n",
    "        descriptor_names = ['a0.25_rp1.0', 'a0.25_rp1.5', 'a0.25_rp2.0', 'a0.25_rp2.5',\n",
    "                            'a0.25_rp3.0', 'a0.5_rp1.0', 'a0.5_rp1.5', 'a0.5_rp2.0', 'a0.5_rp2.5',\n",
    "                            'a0.5_rp3.0', 'a1.0_rp1.0', 'a1.0_rp1.5', 'a1.0_rp2.0', 'a1.0_rp2.5',\n",
    "                            'a1.0_rp3.0', ]\n",
    "        target_name = 'Etot'\n",
    "    else:\n",
    "        raise ValueError(\"unknown data_name={}\".format(data_name))\n",
    "    return df, descriptor_names, target_name\n",
    "\n",
    "\n",
    "g_df, g_descriptor_names, g_target_name = get_data(DATA_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_Xraw = g_df[g_descriptor_names].values\n",
    "g_y = g_df[g_target_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "g_scaler = StandardScaler()\n",
    "g_scaler.fit(g_Xraw)\n",
    "g_X = g_scaler.transform(g_Xraw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_combinations(n, m=None):\n",
    "    \"\"\"make the iterator of all combinations\n",
    "\n",
    "    Args:\n",
    "        n (int): the number of descriptors\n",
    "        m (int, optional): the maximum number of descriptors. Defaults to None.\n",
    "\n",
    "    Yields:\n",
    "        tuple(int, ...): a set of descriptors\n",
    "    \"\"\"\n",
    "    seq = range(n)\n",
    "    if m is None:\n",
    "        m = n\n",
    "    for i in range(1, m+1):\n",
    "        for x in itertools.combinations(seq, i):\n",
    "            yield x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def fit_cv_X(x, y, mode=\"Linear\", nfold=5, nfold_model=3):\n",
    "    \"\"\"make CV scores \n",
    "\n",
    "    Args:\n",
    "        x (np.array): descriptor\n",
    "        y (np.array): target values\n",
    "        mode (str, optional): a type of regression. \"Linear\" or \"Ridge\" or \"RF\". Defaults to \"Linear\".\n",
    "        nfold (int, optional): the number of foldings in linear regression. Defaults to 5.\n",
    "        nfold_model (int, optional): the number foldings in RdigeCV. Defaults to 3.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: unknown mode\n",
    "\n",
    "    Returns:\n",
    "        tuple containing\n",
    "        \n",
    "        - float: the mean value of the score\n",
    "        - float: the stddev vlaue of the score\n",
    "        - np.array: coefficients of the regression for linear models, feature importance for randomforest mdoel.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=nfold, shuffle=True, random_state=6)\n",
    "    kf_model = KFold(n_splits=nfold_model, shuffle=True, random_state=6)\n",
    "\n",
    "    meanlist = []\n",
    "    varlist = []\n",
    "\n",
    "    if mode == \"Linear\":\n",
    "        reg = LinearRegression(fit_intercept=True, normalize=False)\n",
    "    elif mode == \"Ridge\":\n",
    "        reg = RidgeCV(cv=kf_model, fit_intercept=True, normalize=False)\n",
    "    elif mode == \"RF\":\n",
    "        reg = RandomForestRegressor(n_estimators=10)\n",
    "    else:\n",
    "        raise ValueError(\"unknown mode=\", mode)\n",
    "\n",
    "    scorelist = cross_val_score(\n",
    "        reg, x, y, scoring=make_scorer(r2_score), cv=kf)\n",
    "\n",
    "    # 平均\n",
    "    mean = np.mean(scorelist)\n",
    "    # 標準偏差\n",
    "    std = np.std(scorelist)\n",
    "\n",
    "    # モデルを作り直す．\n",
    "    reg.fit(x, y)\n",
    "\n",
    "    if mode in [\"Linear\", \"Ridge\"]:\n",
    "        return mean, std, reg.coef_\n",
    "    elif mode == \"RF\":\n",
    "        return mean, std, reg.feature_importances_\n",
    "    else:\n",
    "        raise ValueError(\"unknown mode=\", mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict_combinations(x, y, regressionmodel, descriptor_names, have_progressbar=False, max_component=None):\n",
    "    \"\"\"accumulate the result of exhaustive search\n",
    "\n",
    "    return valueはkeys()として\"combination\", \"score_mean\", \"score_std\": \"coef\"を含む．\n",
    "\n",
    "    Args:\n",
    "        x (np.array): descriptor\n",
    "        y (np.array): target value\n",
    "        regressionmodel (str): regression model name\n",
    "        descriptor_names (list[str]): 説明変数名リスト．\n",
    "        have_progressbar (bool, optional): have progress bar. Defaults to False.\n",
    "        max_component (int, optional): the maximum number of descriptors. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        dict: results.  a list of combination, mean,variance,coefficient\n",
    "    \"\"\"\n",
    "    print_indicatorlabel = False\n",
    "\n",
    "    n = x.shape[1]\n",
    "    if max_component is None:\n",
    "        max_component = n\n",
    "\n",
    "    combi_list = []\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    coef_list = []\n",
    "\n",
    "    for ncombi, s in enumerate(all_combinations(n, max_component)):\n",
    "        pass\n",
    "\n",
    "    if have_progressbar:\n",
    "        bar = progressbar.ProgressBar(max_value=ncombi+1)\n",
    "\n",
    "    for i, icombi in enumerate(all_combinations(n, max_component)):\n",
    "        if have_progressbar:\n",
    "            bar.update(i+1)\n",
    "\n",
    "        icombi = np.array(icombi)\n",
    "        combi = np.array(descriptor_names)[np.array(icombi)]\n",
    "        combi_list.append(icombi)\n",
    "        if print_indicatorlabel:\n",
    "            print(\"indicators\", combi)\n",
    "        xtry = x[:, icombi]\n",
    "        ytry = y\n",
    "        mean, std, coef = fit_cv_X(xtry, ytry, regressionmodel)\n",
    "        mean_list.append(mean)\n",
    "        std_list.append(std)\n",
    "        # The first element　of coef is the coefficient to y\n",
    "        coef_list.append(coef.ravel())\n",
    "\n",
    "    mean_list = np.array(mean_list)\n",
    "    std_list = np.array(std_list)\n",
    "\n",
    "    return {\"combination\": combi_list, \"score_mean\": mean_list, \"score_std\": std_list, \"coef\": coef_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def save_df(df_result, descriptor_names,  savefile):\n",
    "    \"\"\"df_resultを保存する．\n",
    "\n",
    "    Args:\n",
    "        df_result (pd.DataFrame): データ\n",
    "        descriptor_names (list[str]): 説明変数名リスト\n",
    "        savefile (str): 保存ファイル名\n",
    "    \"\"\"\n",
    "    # print(descriptor)\n",
    "    descriptor_names = np.array(descriptor_names)\n",
    "    # df_result.to_csv(\"TC_ReCo_ES.csv\")\n",
    "    combinationlist = []\n",
    "    for x in df_result[\"combination\"].values:\n",
    "        x2 = descriptor_names[np.array(x)]\n",
    "        combinationlist.append(\"|\".join(x2))\n",
    "    df_result[\"descriptor\"] = combinationlist\n",
    "    with open(savefile, \"wb\") as f:\n",
    "        pickle.dump(df_result, f)\n",
    "\n",
    "\n",
    "g_savefile = \"ESresult_{}_{}_{}.pickle\".format(\n",
    "    REGRESSION_MODEL, g_target_name, DATA_NAME)\n",
    "print(\"filename\", g_savefile)\n",
    "if not os.path.exists(g_savefile):\n",
    "    g_result = fit_and_predict_combinations(g_X, g_y, REGRESSION_MODEL,\n",
    "                                            g_descriptor_names,\n",
    "                                            have_progressbar=g_have_progressbar)\n",
    "    g_df_score = pd.DataFrame(g_result).sort_values(\n",
    "        by=\"score_mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    save_df(g_df_score, g_descriptor_names,  g_savefile)\n",
    "\n",
    "with open(g_savefile, \"rb\") as f:\n",
    "    g_df_result = pickle.load(f)\n",
    "    print(\"load\", g_savefile)\n",
    "g_df_score = g_df_result[['combination', 'score_mean', 'score_std', 'coef']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_r2_hist(df, xlim=None, comment=None, metadata: dict=METADATA, \n",
    "                 tickfontsize=15, titlefontsize=15, labelfontsize=15):\n",
    "    \"\"\"R2のDOSを図示する．\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): データ\n",
    "        xlim (tuple(float, float), optional): 図のx range. Defaults to None.\n",
    "        filename (str, optional): 保存ファイル名. Defaults to None.\n",
    "        tickfontsize (int, optional): ticsk font size. Defaults to 15.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    df.hist(\"score_mean\", bins=100, ax=ax)\n",
    "    ax.set_title(ax.get_title(), fontsize=titlefontsize)\n",
    "    ax.set_xlabel(\"R2\", fontsize=titlefontsize)\n",
    "    ax.set_ylabel(\"occurrence\", fontsize=titlefontsize)\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    ax.tick_params(axis='x', labelsize=tickfontsize)\n",
    "    ax.tick_params(axis='y', labelsize=tickfontsize)\n",
    "    fig.tight_layout()\n",
    "    filename = \"_\".join([metadata[\"prefix\"],metadata[\"dataname\"],\n",
    "                         metadata[\"regtype\"],str(comment)])+\".png\"\n",
    "    fig.savefig(os.path.join(metadata[\"outputdir\"],filename))\n",
    "    print(\"saved to\",filename)\n",
    "\n",
    "show_r2_hist(g_df_score,comment=\"fullrange\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拡大\n",
    "show_r2_hist(g_df_score, xlim=(-0.5, 1.0), comment='-05to10')\n",
    "show_r2_hist(g_df_score, xlim=(0.4, 0.85), comment='04to085')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coeffix(descriptor, combilist, coeflist):\n",
    "    \"\"\"表示のために 係数０の部分を加えて係数を作りなおす．\n",
    "\n",
    "    Args:\n",
    "        descriptor (list[str]): all the descriptor names\n",
    "        combilist (list): a list of descriptor combinations of the models\n",
    "        coeflist (np.array): a list of coefficients of the models\n",
    "\n",
    "    Returns:\n",
    "        list: a list of coefficnets whose length is the same as the length of all the descriptors\n",
    "    \"\"\"\n",
    "    n = len(descriptor)\n",
    "    coeffixlist = []\n",
    "    for combi, coef in zip(combilist, coeflist):\n",
    "\n",
    "        coeffix = np.zeros((n))\n",
    "        # if combi=[1,2], and coef=[val1,val2], then coeffix=[0,val1,val2,0,0]\n",
    "        for i, id in enumerate(combi):\n",
    "            coeffix[id] = coef[i]\n",
    "\n",
    "        # 都合でlistに直す．\n",
    "        coeffixlist.append(list(coeffix))\n",
    "    return coeffixlist\n",
    "\n",
    "\n",
    "g_coeffixlist = calculate_coeffix(g_descriptor_names,\n",
    "                                  g_df_score[\"combination\"].values, g_df_score[\"coef\"].values)\n",
    "g_df_coef = pd.DataFrame(g_coeffixlist, columns=g_descriptor_names)\n",
    "g_df_result = pd.concat([g_df_score, g_df_coef], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def show_weight_diagram(df_result, descriptor_names, nmax=50, \n",
    "                        comment='index_vs_abscoef',\n",
    "                       metadata:dict=METADATA,\n",
    "                       tickfontsize=15, figsize=(10,5)):\n",
    "    \"\"\"weight diagramの表示\n",
    "\n",
    "    Args:\n",
    "        df_result (pd.DataFrame): data\n",
    "        descriptor_names (List[str]): 説明変数カラムリスト\n",
    "        nmax (int, optional): the maximum number of the data to show. Defaults to 50.\n",
    "        comment (str, optional): 表示ファイル用コメント. Defaults to 'index_vs_abscoef'.\n",
    "        metadata (dict): 表示用データ\n",
    "        tickfontsize (int, optional): ticks font size. Defaults to 15.\n",
    "        figsize (Tuple[float], optional): figure size. Defaults to (7,5).\n",
    "    \"\"\"\n",
    "    x = df_result.loc[:nmax, descriptor_names].values\n",
    "    x = np.log10(np.abs(x))\n",
    "    df_x = pd.DataFrame(x, columns=descriptor_names).replace(\n",
    "        [-np.inf, np.inf], np.nan)\n",
    "    df_weight_diagram = df_x.fillna(-3)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    # ax.set_title(\"log10(abs(coef))\")\n",
    "    sns.heatmap(df_weight_diagram.T, ax=ax)\n",
    "    ax.set_ylim((-0.5, df_weight_diagram.shape[1]+0.5))\n",
    "    ax.tick_params(axis='x', labelsize=tickfontsize)\n",
    "    ax.tick_params(axis='y', labelsize=tickfontsize)    \n",
    "    fig.tight_layout()\n",
    "    filename = \"_\".join([metadata[\"prefix\"],metadata[\"dataname\"],\n",
    "                         metadata[\"regtype\"],str(comment)])+\".png\"\n",
    "    fig.savefig(os.path.join(metadata[\"outputdir\"],filename))    \n",
    "    print(filename)\n",
    "\n",
    "show_weight_diagram(g_df_result, g_descriptor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_indicator_diagram(df_result, descriptor_names, nmax=50):\n",
    "    \"\"\"indicator diagramを表示する．\n",
    "\n",
    "    Args:\n",
    "        df_result (pd.DataFrame): data\n",
    "        nmax (int, optional): the maximum number of the data to show. Defaults to 50.\n",
    "    \"\"\"\n",
    "    x = df_result[descriptor_names].values != 0\n",
    "    df_indicator_diagram = pd.DataFrame(x, columns=descriptor_names)\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(df_indicator_diagram.loc[:nmax, :].T, ax=ax)\n",
    "    ax.set_ylim((-0.5, df_indicator_diagram.shape[1]+0.5))\n",
    "    fig.tight_layout()\n",
    "    return df_indicator_diagram\n",
    "\n",
    "g_df_indicator_diagram = show_indicator_diagram(\n",
    "    g_df_result, g_descriptor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_score_mean_std(df_result, comment: str=\"mean_std\", \n",
    "                        metadata: dict=METADATA,\n",
    "                       tickfontsize=15,labelfontsize=15,legendfontsize=15):\n",
    "    \"\"\"show index vs mean+-std.\n",
    "    \n",
    "    Args:\n",
    "        df_result (pd.DataFrame): データ.\n",
    "        comment (str): コメント. Defaults to \"mean_std\".\n",
    "        metadata (dict): 表示用データ.  Defaults to METADATA.\n",
    "        tickfontsize (int, optional): ticks font size. Defaults to 15.\n",
    "        labelfontsize (int, optional): label font size. Defaults to 15.\n",
    "        legendfontsize (int, optional): legend font size. Defaults to 15.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    df_result.loc[:50, :].plot(y=\"score_mean\", yerr=\"score_std\", ax=ax)\n",
    "    ax.set_xlabel(\"index\", fontsize=labelfontsize)\n",
    "    ax.set_ylabel(\"$R^2$\", fontsize=labelfontsize)\n",
    "    ax.tick_params(axis='x', labelsize=tickfontsize)\n",
    "    ax.tick_params(axis='y', labelsize=tickfontsize)\n",
    "    ax.legend(fontsize=legendfontsize)\n",
    "    fig.tight_layout()\n",
    "    filename = \"_\".join([metadata[\"prefix\"],metadata[\"dataname\"],\n",
    "                         metadata[\"regtype\"],str(comment)])+\".png\"\n",
    "    fig.savefig(os.path.join(metadata[\"outputdir\"],filename))    \n",
    "    print(filename)\n",
    "    \n",
    "show_score_mean_std(g_df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_counts(df_result, descriptor_names, sentense, ratio=False):\n",
    "    \"\"\"\n",
    "    説明変数が用いられた回数を計算する．\n",
    "\n",
    "    Args:\n",
    "        df_result (pd.DataFrame): データ\n",
    "        descriptor_names (list[str]): 説明変数名リスト．\n",
    "        sentense (str): query文\n",
    "        ratio (bool, optional): 回数(False), 割合(True)を返す． Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 回数もしくは割合データ．\n",
    "    \"\"\"\n",
    "    x = df_result[descriptor_names].values != 0  # 係数が０でない．＝その説明変数が含まれるモデル．\n",
    "    df_indicator_diagram = df_result.copy()\n",
    "    df_indicator_diagram.loc[:, descriptor_names] = x\n",
    "\n",
    "    dfq = df_indicator_diagram.query(sentense)\n",
    "    print(\"all=\", dfq.shape[0])\n",
    "    if ratio:\n",
    "        return np.sum(dfq[descriptor_names], axis=0)/dfq.shape[0]\n",
    "    else:\n",
    "        return np.sum(dfq[descriptor_names], axis=0)\n",
    "\n",
    "\n",
    "def make_block_weight_list(df_result, descriptor_names, querylist, \n",
    "                           comment='block_weight_list',\n",
    "                          metadata:str = METADATA,\n",
    "                          tickfontsize=15):\n",
    "    \"\"\"\n",
    "    querylistのblock weight diagramを計算する．\n",
    "\n",
    "    Args:\n",
    "        df_result (pd.DataFrame): データ．\n",
    "        descriptor_names (list[str]): 説明名リスト．\n",
    "        querylist (list[str]): query文リスト．\n",
    "        comment (str): 表示ファイル用コメント. Defaults to 'block_weight_list'.\n",
    "        metadata (dict): 表示ファイル用データ. Defaults to METADATA.\n",
    "    Returns:\n",
    "        pd.DataFrame: block weight diagram.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for sentense in querylist:\n",
    "        # 前の図に合わせるためにdescriptor_namesの順序を逆にする．\n",
    "        t = make_counts(\n",
    "            df_result, descriptor_names[::-1], sentense, ratio=True)\n",
    "        result.append(t)\n",
    "    dfq = pd.DataFrame(result, index=querylist)\n",
    "    display(dfq)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    sns.heatmap(dfq.T, ax=ax)  # 前の図に合わせるためにtransposeする．\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), ha='right', rotation=45)\n",
    "    ax.tick_params(axis='x', labelsize=tickfontsize)\n",
    "    ax.tick_params(axis='y', labelsize=tickfontsize)\n",
    "    fig.tight_layout()\n",
    "    filename = \"_\".join([metadata[\"prefix\"],metadata[\"dataname\"],\n",
    "                         metadata[\"regtype\"],str(comment)])+\".png\"\n",
    "    fig.savefig(os.path.join(metadata[\"outputdir\"],filename))    \n",
    "    print(filename)    \n",
    "\n",
    "if DATA_NAME == \"ReCo\":\n",
    "    if REGRESSION_MODEL == \"Linear\":\n",
    "        g_querylist = [\"score_mean<0.15\", \"score_mean>0.15 and score_mean<0.5\",\n",
    "                       \"score_mean>0.5 and score_mean<0.7\", \"score_mean>0.7\"]\n",
    "        make_block_weight_list(g_df_result, g_descriptor_names, g_querylist)\n",
    "    if REGRESSION_MODEL == \"RF\":\n",
    "        g_querylist = [\"score_mean<0.0\",\n",
    "                       \"0.6<score_mean<0.8\", \"score_mean>0.8\", ]\n",
    "        make_block_weight_list(g_df_result, g_descriptor_names, g_querylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_by_index(df_indicator_diagram, descriptor_names, index):\n",
    "    \"\"\"部分データを得るためのデータを作る．\n",
    "\n",
    "    return valueはindexで指定された範囲で，\n",
    "    descriptor_names（０でない数）+\"N\"（データインスタンス総数）をカラムに持つデータになる．\n",
    "\n",
    "    Args:\n",
    "        df_indicator_diagram (pd.DataFrame): indicator diagram データ\n",
    "        descriptor_names (list[str]): 説明変数名リスト\n",
    "        index (list[int]): データインスタンスの部分indexリスト\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: indicator diagram部分データ\n",
    "    \"\"\"\n",
    "    dfq = df_indicator_diagram.iloc[index, :]\n",
    "    print(\"all=\", dfq[descriptor_names].shape[0])\n",
    "    df_all = pd.DataFrame({\"N\": [dfq[descriptor_names].shape[0]]},)\n",
    "    dfq_sum = dfq[descriptor_names].astype(int).sum(axis=0)\n",
    "    df1 = pd.DataFrame(dfq_sum).T\n",
    "\n",
    "    return pd.concat([df1, df_all], axis=1)\n",
    "    # print(np.sum(dfq[descriptor_names], axis=0))\n",
    "\n",
    "\n",
    "def make_all_ind_by_index(df_indicator_diagram, descriptor_names, regionindex, regionsize):\n",
    "    \"\"\"各領域の非ゼロの説明変数の割合を得る．\n",
    "\n",
    "    regionindex=[0,1,..,N]\n",
    "    for i in regionindex:\n",
    "        region = [ i*regionsize, (i+1)*regionsize ]\n",
    "    と各data instance index領域を定義する．\n",
    "\n",
    "    Args:\n",
    "        df_indicator_diagram (pd.DataFrame): データ\n",
    "        descriptor_names (list[str]): 説明変数名リスト\n",
    "        regionindex (list[int])): 領域インデックスリスト\n",
    "        regionsize (int)): 領域サイズ\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 分割領域ごとのデータ\n",
    "    \"\"\"\n",
    "    df_ind_list = []\n",
    "    for i in regionindex:\n",
    "        region = list(range(i*regionsize, (i+1)*regionsize))\n",
    "        df_ind = make_df_by_index(\n",
    "            df_indicator_diagram, descriptor_names, region)\n",
    "        df_ind_list.append(df_ind)\n",
    "    _df = pd.concat(df_ind_list, axis=0).reset_index(drop=True)\n",
    "\n",
    "    names = list(_df.columns)\n",
    "    names.remove(\"N\")\n",
    "    v0 = _df[\"N\"]\n",
    "    for name in names:\n",
    "        _df[name] = _df[name]/v0\n",
    "        \n",
    "    if False:\n",
    "        fig, ax = plt.subplots()\n",
    "        _df[names].T.plot(ax=ax)\n",
    "        ax.set_ylabel(\"frequency\")\n",
    "        ax.set_xticks(list(range(len(names))))\n",
    "        ax.set_xticklabels(names, rotation=90)\n",
    "        ax.set_ylim((0, 1))\n",
    "    return _df\n",
    "\n",
    "\n",
    "g_regions = [_i for _i in range(5)]\n",
    "g_regionsize = 300\n",
    "g_df_imp_by_index = make_all_ind_by_index(\n",
    "    g_df_indicator_diagram, g_descriptor_names, g_regions, g_regionsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_r2_by_index(df_result, regions, regionsize):\n",
    "    \"\"\"各領域の代表値のR2を表示する．\n",
    "\n",
    "    regions = [0,...,N-1]\n",
    "    for i in regions:\n",
    "        # i*regionsize番目のR2を表示する．\n",
    "        dfp = df_result.iloc[[regionsize*i], :]\n",
    "\n",
    "    Args:\n",
    "        df_result (pd.DataFrame): 全データインスタンスのデータ\n",
    "        regions (list[int]): 領域リスト\n",
    "        regionsize (int): 領域サイズ\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    regions = np.array(regions)\n",
    "    for i in regions:\n",
    "        dfp = df_result.iloc[[regionsize*i], :] # 間違っている？\n",
    "        dfp.plot(y=\"score_mean\", yerr=\"score_std\", ax=ax,label=\"yerr at {}th\".format(regionsize*i))\n",
    "    dfp1 = df_result.loc[regionsize*regions, [\"score_mean\"]]\n",
    "    dfp1.plot(y=\"score_mean\", ax=ax)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.set_ylabel(\"R2\")\n",
    "    ax.set_xlabel(\"Nst model\")\n",
    "\n",
    "show_r2_by_index(g_df_result, g_regions, g_regionsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def show_df_imp_by_index(df_imp_by_index, descriptor_names, regions, regionsize,\n",
    "                         comment: str = \"importancebyindex\", \n",
    "                         metadata: dict= METADATA,\n",
    "                         tickfontsize=15, labelfontsize=15, legendfontsize=15):\n",
    "    \"\"\"各領域の説明変数の頻度を図示する．\n",
    "\n",
    "    Args:\n",
    "        df_imp_by_index (list[pd.DataFrame]): _description_\n",
    "        descriptor_names (list[str]): 説明変数名リスト\n",
    "        regions (list[int])): 領域リスト\n",
    "        regionsize (int): 領域サイズ\n",
    "        comment (str): 表示用コメント. Defaults to \"importancebyindex\".\n",
    "        metadata (dict): 表示用データ. Defaults to METADATA. \n",
    "        tickfontsize (int, optional): ticks font size. Defaults to 15.\n",
    "        labelfontsize (int, optional): ticks font size. Defaults to 15.\n",
    "        legendfontsize (int, optional): legend font size. Defaults to 15.\n",
    "    \"\"\"\n",
    "    xticks_str = []\n",
    "    for i in regions:\n",
    "        xticks_str.append(\"[{}:{}]\".format(i*regionsize, (i+1)*regionsize))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    if False:\n",
    "        df_imp_by_index[descriptor_names].plot(marker=\"o\", ax=ax)\n",
    "    else:\n",
    "        marker_list = [\".\", \"o\", \"v\", \"^\", \"<\", \">\"]\n",
    "        marker_list += [\"8\", \"s\", \"p\", \"*\", \"h\", \"H\", \"+\", \"x\", \"D\",\"d\"]\n",
    "        for exp_name, marker in zip(descriptor_names, marker_list):\n",
    "            df_imp_by_index[exp_name].plot(marker=marker, ax=ax)\n",
    "    ax.set_xticks(list(range(len(regions))))\n",
    "    ax.set_xticklabels(xticks_str)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=legendfontsize)\n",
    "    ax.set_ylabel(\"occurrence\", fontsize=labelfontsize)\n",
    "    ax.tick_params(axis='x', rotation=90, labelsize=tickfontsize)\n",
    "    ax.tick_params(axis='y', labelsize=tickfontsize)    \n",
    "    fig.tight_layout()\n",
    "    filename = \"_\".join([metadata[\"prefix\"],metadata[\"dataname\"],\n",
    "                         metadata[\"regtype\"],str(comment)])+\".png\"\n",
    "    fig.savefig(os.path.join(metadata[\"outputdir\"],filename))    \n",
    "    print(filename)    \n",
    "\n",
    "display(g_df_imp_by_index)\n",
    "show_df_imp_by_index(g_df_imp_by_index, g_descriptor_names,\n",
    "                     g_regions, g_regionsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_combination_R2(df, descriptor_names):\n",
    "    nlist = []\n",
    "    for combi in df[\"combination\"]:\n",
    "        nlist.append(len(combi))\n",
    "    df[\"ncombi\"] = nlist\n",
    "    del nlist\n",
    "    nresult=[]\n",
    "    for n in range(1,len(descriptor_names)+1):\n",
    "        _df = df[df[\"ncombi\"]==n]\n",
    "        print(_df.shape,n)\n",
    "        _df.sort_values(by=\"score_mean\", inplace=True, ascending=False)\n",
    "        _df.reset_index(drop=True, inplace=True)\n",
    "        nresult.append([n,_df.loc[0,\"score_mean\"],_df.loc[0,\"score_std\"]])\n",
    "    _df = pd.DataFrame(nresult, columns=[\"n\",\"score_mean\",\"score_std\"])\n",
    "    return _df\n",
    "\n",
    "g_df_combination_R2 = make_combination_R2(g_df_result, g_descriptor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df_combination_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_R2(df_combination_R2, df_result, nselect, comment=None, metadata=METADATA,\n",
    "             labelfontsize=15, tickfontsize=15, legendfontsize=12):\n",
    "    \"\"\"plot n_vs R2 and index vs R2.\n",
    "    \n",
    "    Args:\n",
    "        df_combination_R2 (pd.DataFrame): data of ncombination, R2).\n",
    "        df_result (pd.DataFrame): exhausitve result.\n",
    "        nselect (int): number of selection.\n",
    "        comment (str): comment added to png filename.\n",
    "        metadata (dict): data for png.\n",
    "        labelfontsize (int, optional): label font size. Defaults to 15.\n",
    "        tickfontsize (int, optional): ticks font size. Defaults to 15.\n",
    "        legendfontsize (int, optional): legend font size. Defaults to 15.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1,2)\n",
    "    ax = axes[0]\n",
    "    df_combination_R2.plot(x=\"n\",y=\"score_mean\", yerr=\"score_std\", ax=ax)\n",
    "    ax.set_ylabel(\"$R^2_{test}$\", fontsize=labelfontsize)\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=labelfontsize)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.tick_params(axis='x', labelsize=tickfontsize)\n",
    "    ax.tick_params(axis='y', labelsize=tickfontsize)   \n",
    "    ax.legend(fontsize=legendfontsize, loc='lower right')\n",
    "    \n",
    "    ax = axes[1]\n",
    "    _df = df_result[g_df_result[\"ncombi\"]==nselect].reset_index(drop=True)\n",
    "    _df.head(10).plot(y=\"score_mean\",yerr=\"score_std\", ax=ax)\n",
    "    ax.set_ylabel(\"$R^2_{test}$\", fontsize=labelfontsize)\n",
    "    ax.set_xlabel(f\"index\", fontsize=labelfontsize)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_ylim(axes[0].get_ylim())\n",
    "    ax.tick_params(axis='x', labelsize=tickfontsize)\n",
    "    ax.tick_params(axis='y', labelsize=tickfontsize)    \n",
    "    ax.legend(fontsize=legendfontsize, loc='lower right')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    filename = \"_\".join([metadata[\"prefix\"],metadata[\"dataname\"],\n",
    "                         metadata[\"regtype\"],str(comment)])+\".png\"\n",
    "    print(filename)\n",
    "    fig.savefig(os.path.join(metadata[\"outputdir\"],filename))\n",
    "    \n",
    "NSELECT = 3\n",
    "plot_n_R2(g_df_combination_R2, g_df_result, NSELECT, comment=\"n_R2_detail_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ncombi_heatmap(df_result, descriptor_names, nselect, ndata, comment, metadata=METADATA,\n",
    "                       labelfontsize=15, tickfontsize=15):\n",
    "    \"\"\"plot index vs heatmap.\n",
    "    \n",
    "    Args:\n",
    "        df_result (pd.DataFrame): exhaustive search results.\n",
    "        descriptor_names (List[str]): descriptor names.\n",
    "        nselect (int): number of selection.\n",
    "        ndata (int): numnber of data instances to choose.\n",
    "        comment (str): comment of png file.\n",
    "        metadata (dict): data for png.\n",
    "        labelfontsize (int, optional): label font size. Defaults to 15.\n",
    "        tickfontsize (int, optional): tick font size. Defaults to 15.\n",
    "    \"\"\"\n",
    "    _df = df_result[df_result[\"ncombi\"]==nselect].reset_index(drop=True)\n",
    "    fig, ax = plt.subplots()\n",
    "    #_df = np.abs(_df[g_descriptor_names])\n",
    "    sns.heatmap(_df.head(ndata)[descriptor_names].T, cmap='Greys', ax=ax)\n",
    "    ax.set_xlabel(\"index\", fontsize=labelfontsize)\n",
    "    ax.tick_params(axis='x', labelsize=tickfontsize)\n",
    "    ax.tick_params(axis='y', labelsize=tickfontsize)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    filename = \"_\".join([metadata[\"prefix\"],metadata[\"dataname\"],\n",
    "                         metadata[\"regtype\"],str(comment),str(nselect), str(ndata)])+\".png\"\n",
    "    print(filename)\n",
    "    plt.savefig(os.path.join(metadata[\"outputdir\"],filename))\n",
    "    \n",
    "NDATA= 6\n",
    "plot_ncombi_heatmap(g_df_result, g_descriptor_names, NSELECT, NDATA, \"ncombi_heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df_result[g_df_result[\"ncombi\"]==NSELECT].reset_index(drop=True).head(NDATA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
