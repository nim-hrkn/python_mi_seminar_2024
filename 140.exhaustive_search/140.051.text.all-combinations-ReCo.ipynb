{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image_text/140_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image_text/140_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image_text/140_03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image_text/140_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anacondaではprogressbar2がインストールされており利用可能なはずです。\n",
    "condaでprogressbar2をインストールする場合は\n",
    "https://anaconda.org/anaconda/progressbar2\n",
    "を参照してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, LassoCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "have_progressbar = True\n",
    "try:\n",
    "    import progressbar \n",
    "except ModuleNotFoundError:\n",
    "    have_progressbar = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメタ設定\n",
    "RANDOM_STATE = 0 # random value for CV.\n",
    "NFOLD = 5 # nfold for CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_data\n",
    "df, DESCRIPTOR_NAMES, TARGET_NAME = get_data.load(\"ReCo\")\n",
    "\n",
    "Xraw = df[DESCRIPTOR_NAMES].values # 生説明変数\n",
    "y = df[TARGET_NAME].values # 目的変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xraw)\n",
    "X = scaler.transform(Xraw) # 規格化された説明変数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lasso_score(X, y, descriptor_names, nfold=5, random_state=0):\n",
    "    \"\"\"calculate Lasso CV score.\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): (N,P), descriptor variables.\n",
    "        y (np.ndarray): (N), target variable.\n",
    "        descriptor_names (List[str]): (P), descriptor names\n",
    "        nfold (int, optional): number of folding in CV. Defaults to 5.\n",
    "        random_state (int, optional): random_state for KFold instance. Defaults to 0.\n",
    "\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=nfold, shuffle=True, random_state=random_state)\n",
    "    meanlist = []\n",
    "    varlist = []\n",
    "\n",
    "    reg = LassoCV(fit_intercept=True, alphas=np.logspace(-5,2,20))\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\")    \n",
    "        reg.fit(X,y)\n",
    "    print(\"alpha=\", reg.alpha_)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\")    \n",
    "        scorelist = cross_val_score(\n",
    "            reg, X, y, scoring=make_scorer(r2_score), cv=kf)\n",
    "    mean = np.mean(scorelist) # 平均\n",
    "    std = np.std(scorelist) # 標準偏差\n",
    "    result = {\"score_mean\": mean, \"score_std\": std}\n",
    "    print(result)\n",
    "    df_coef = pd.DataFrame({\"descriptor\": descriptor_names, \"coef\": reg.coef_}).set_index(\"descriptor\", drop=True)\n",
    "    display(df_coef)\n",
    "    return result\n",
    "    \n",
    "lasso_score = calc_lasso_score(X, y, DESCRIPTOR_NAMES, nfold=NFOLD, random_state=RANDOM_STATE)\n",
    "# モデル全探索を行う前に、LassoのCV scoreと係数を計算する。              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル全探索を行うためのindex組み合わせを作成する関数を作る。\n",
    "def all_combinations(n: int, m: int=None):\n",
    "    \"\"\" nCj, j=1,...,mの組み合わせを出力する。\n",
    "    ```\n",
    "    for icombi in all_combinations(N):\n",
    "        ...\n",
    "    ``` \n",
    "    として用いる。\n",
    "    This returns, for example, (1,2,5). \n",
    "    \n",
    "    Args:\n",
    "        n (int): n of n_C_m. \n",
    "        m (int, optional): m of n_C_m. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: combination\n",
    "    \"\"\"\n",
    "    seq = range(n)\n",
    "    if m is None:\n",
    "        m = n\n",
    "    for i in range(1, m+1):\n",
    "        for x in itertools.combinations(seq, i):\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cv_model(x, y, alpha=0.1, nfold=5, random_state=0):\n",
    "    \"\"\"交差検定でRidge回帰の\n",
    "    \n",
    "    Ridge回帰のalphaを固定する。\n",
    "    CVのscoreはR2 scoreを用いる。\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): (N,P), 説明変数. \n",
    "        y (np.ndarray): (N), 目的変数.\n",
    "        alpha (float): hyperparameter of Ridge. Defaults to 0.001.\n",
    "        nfold (int): 交差検定回数. Defaults to 5.\n",
    "        random_state (int): Defaults to 0.\n",
    "        \n",
    "    Returns:\n",
    "        tuple containing,\n",
    "        float: mean value of scores.\n",
    "        float: stddev value fo scores.\n",
    "        np.ndarray: (P), 回帰係数\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=nfold, shuffle=True, random_state=random_state)\n",
    "    meanlist = []\n",
    "    varlist = []\n",
    "    reg = Ridge(fit_intercept=True, alpha=alpha)\n",
    "        \n",
    "    scorelist = cross_val_score(\n",
    "        reg, x, y, scoring=make_scorer(r2_score), cv=kf)\n",
    "    mean = np.mean(scorelist) # 平均\n",
    "    std = np.std(scorelist) # 標準偏差\n",
    "    reg.fit(x, y) # 回帰モデルを作り直し係数を得る．\n",
    "    return mean, std, reg.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下でprogressbar関係のエラーが起きる場合はこのセルの先頭で\n",
    "```\n",
    "have_progressbar = False\n",
    "```\n",
    "を追加してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_list = [] # 用いる説明変数の組み合わせ\n",
    "mean_list = [] # CV score平均比\n",
    "std_list = [] # CV score stdev\n",
    "coef_list = [] # 回帰係数\n",
    "\n",
    "P = X.shape[1]\n",
    "ncombi = 2**P-1\n",
    "if have_progressbar: # progressbarをinstallしていると何％まで進んだかの表示がなされる。\n",
    "    bar = progressbar.ProgressBar(max_value=ncombi)\n",
    "for i, icombi in enumerate(all_combinations(P)):\n",
    "    if have_progressbar:\n",
    "        bar.update(i+1)\n",
    "\n",
    "    combi_list.append(icombi) # icombi = (1,2,5)など。sizeをP'と置く。\n",
    "    xtry = X[:, icombi] # xtry(N,P'), icombiの列だけ選ばれる.\n",
    "    ytry = y # (N)\n",
    "    mean, std, coef = make_cv_model(xtry, ytry, nfold=NFOLD, random_state=RANDOM_STATE)\n",
    "    \n",
    "    mean_list.append(mean) # 計算結果と計算条件をためていく。\n",
    "    std_list.append(std)\n",
    "    coef_list.append(coef)\n",
    "\n",
    "mean_list = np.array(mean_list)\n",
    "std_list = np.array(std_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from all_combinations_misc import plot_r2_hist\n",
    "# 全探索結果をDataFrameに変換する。\n",
    "df_score = pd.DataFrame({\"combination\": combi_list, \n",
    "                         \"score_mean\": mean_list, \n",
    "                         \"score_std\": std_list, \"coef\": coef_list})\n",
    "df_score.sort_values(by=\"score_mean\", ascending=False, inplace=True)\n",
    "df_score.reset_index(drop=True, inplace=True)\n",
    "fig, ax = plot_r2_hist(df_score,xlim=(-0.4,1)) # R2の頻度を可視化する。\n",
    "ax.plot((lasso_score[\"score_mean\"],lasso_score[\"score_mean\"]),\n",
    "        ax.get_ylim(), color=\"red\", label=\"Lasso\") # LassoのR2を赤色で可視化する。\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anacondaではインストールされているはずですが、plotly expressのインストールは\n",
    "# https://anaconda.org/plotly/plotly_express\n",
    "# を参照してください。Macではこのセル動作しないとかもしれません。\n",
    "import plotly.express as px\n",
    "# 分布境界を得るためにinteractive環境を用いる。\n",
    "fig = px.histogram(df_score, nbins=1000, x=\"score_mean\", range_x=(0.7,0.95)) \n",
    "# fig.show()\n",
    "plt.show()\n",
    "\n",
    "# peakが四つあるとして境界は以下の通りに読み取れる。\n",
    "# [0.913:]\n",
    "# [0.885:0.913]\n",
    "# [0.849:0.885]\n",
    "# [0.7:0.849]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from all_combinations_misc import calculate_coeffix\n",
    "# 回帰モデルは(1,2), (1,2,3,4,6)などでXの大きさが異なる。\n",
    "# 使っていない説明変数の係数＝0として、係数ベクトルを作り直す。\n",
    "coeffixlist = calculate_coeffix(DESCRIPTOR_NAMES,\n",
    "                                df_score[\"combination\"].values, \n",
    "                                df_score[\"coef\"].values)\n",
    "# coeffixlist: (N,P)、並びはDESCRIPTOR_NAMESの順。\n",
    "df_coef = pd.DataFrame(coeffixlist, columns=DESCRIPTOR_NAMES)\n",
    "df_result = pd.concat([df_score, df_coef], axis=1) # scoreと係数のDataFrameを別々に作ったので結合する。\n",
    "df_result.sort_values(by=\"score_mean\", ascending=False, inplace=True) # 平均値でソートしておく。\n",
    "df_result.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5)) # matplotlib の図と座標軸を得る\n",
    "ax = df_result.iloc[:200, :].plot(y=\"score_mean\", yerr=\"score_std\", ax=ax) # 200番目まで。\n",
    "ax.errorbar([200], [lasso_score[\"score_mean\"]], yerr=[lasso_score[\"score_std\"]], marker=\"x\") # 201番めにLassoの値を表示する。\n",
    "ax.set_xlabel(\"index\") # 横軸名\n",
    "ax.set_ylabel(\"$R^2$\") # 縦軸名\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "# R2平均値が大きい順に、R2平均値と標準偏差を並べて可視化する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from all_combinations_misc import plot_weight_diagram\n",
    "plot_weight_diagram(df_result, DESCRIPTOR_NAMES, nmax=200, figsize=(10,5))\n",
    "# index順に200位まで各説明変数の大きさをheatmapで可視化する。\n",
    "# heatmapはlog scaleで表示される。\n",
    "# log(0)は-3を表す黒で示される。Warningも出る。\n",
    "# 見方:\n",
    "# 明る色は重要。\n",
    "# 必ず使われている説明変数は重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from all_combinations_misc import plot_weight_diagram3d\n",
    "plot_weight_diagram3d(df_result,DESCRIPTOR_NAMES) \n",
    "# 色の差はわかりにくいので、和を１に規格化した重要度をlinear scaleで3D 表示する。\n",
    "# しかし細部がわかりにくい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from all_combinations_misc import make_and_plot_block_weight_list\n",
    "querylist = [\"score_mean<0.15\", \"score_mean>0.15 and score_mean<0.5\",\n",
    "               \"score_mean>0.5 and score_mean<0.7\", \"score_mean>0.7\"]\n",
    "# 各領域で用いられた説明変数の頻度を得る。\n",
    "# 頻度=1は必ず使われた。\n",
    "make_and_plot_block_weight_list(df_result, DESCRIPTOR_NAMES, querylist, figsize=(10,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最もR2が大きなpeakをより詳細に調べる。\n",
    "querylist = [\"score_mean>0.7 and score_mean<=0.849\", \"score_mean>0.849 and score_mean<=0.885\",\n",
    "             \"score_mean>0.885 and score_mean<=0.913\", \"score_mean>0.913\"]\n",
    "make_and_plot_block_weight_list(df_result, DESCRIPTOR_NAMES, querylist, figsize=(10,5))\n",
    "# 特に、score_meanが大きい領域で、S4fもまた重要らしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_meanに対して、\"C_R\", \"C_T\", \"vol_per_atom\",\"S4f\"の組み合わせを可視化する。\n",
    "from all_combinations_misc import make_combination_stacked_bar\n",
    "make_combination_stacked_bar(df_result.query(\"score_mean>0.7\"),\n",
    "                            column_names=(\"C_R\", \"C_T\", \"vol_per_atom\",\"S4f\"),\n",
    "                            figsize=(15,5), output_dir=\"image_executed\")\n",
    "# special_column_namesのcombinationでscoreに対してカテゴリ分けする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_meanが最も大きなモデル\n",
    "df_result.loc[[0],DESCRIPTOR_NAMES].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevance analysis\n",
    "# 説明変数一つに対して適用する。\n",
    "\n",
    "relevance = [] # 結果を貯めるリスト\n",
    "score_max = df_result[\"score_mean\"].values.max() # 全モデルの最大score\n",
    "for name in DESCRIPTOR_NAMES:\n",
    "    score_minus = df_result[df_result[name]==0][\"score_mean\"].values.max()\n",
    "    # descriptorを含まないモデルの最大scoreを出す。\n",
    "    dr2 = score_max-score_minus # scoreの差\n",
    "    relevance.append([name,dr2])\n",
    "pd.DataFrame(relevance, columns=[\"descriptor\", \"dR2\"]).sort_values(by=\"dR2\", ascending=False)\n",
    "# データフレームで可視化する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevance analysis\n",
    "# 説明変数２つの組に対して適用する。\n",
    "\n",
    "relevance = []\n",
    "for combi in itertools.combinations(DESCRIPTOR_NAMES,2):\n",
    "    df_q = df_result.copy()\n",
    "    for s in combi:\n",
    "        df_q = df_q[df_q[s]==0]\n",
    "    score_minus = df_q[\"score_mean\"].values.max()\n",
    "    # descriptorを含まないモデルの最大scoreを出す。\n",
    "    dr2 = score_max-score_minus # scoreの差\n",
    "    relevance.append([\",\".join(combi),dr2])\n",
    "df_rel = pd.DataFrame(relevance, columns=[\"descriptor\", \"dR2\"]).sort_values(by=\"dR2\", ascending=False)\n",
    "df_rel.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image_text/140_05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image_text/140_06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image_text/140_07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image_text/140_08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image_text/140_09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image_text/140_10.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
