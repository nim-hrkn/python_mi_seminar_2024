{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pymatgen.core import Element\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT15 = False # True: select top 15, False: select all \n",
    "\n",
    "MIN_SUPPORT = 0.1\n",
    "MIN_CONFIDENCE = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "FILENAME = \"atom_transaction.json\"\n",
    "# FILENAME = \"atom_transaction_additional.json\"\n",
    "\n",
    "ROOT = \"..\"\n",
    "filepath = os.path.join(\"data\", FILENAME)\n",
    "with open(filepath,\"r\") as f:\n",
    "    g_transaction = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA = {\"outputdir\": \"image_executed\", \"prefix\": \"freqmining\", \n",
    "              \"dataname\": FILENAME.replace(\".\",\"_\"), \"support\": str(MIN_SUPPORT),\n",
    "           \"confidence\": str(MIN_CONFIDENCE) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれのtransactionのitemの数を表示する．各transactionの個数がバラバラであることが分かる．\n",
    "for name, value in g_transaction.items():\n",
    "    print(name, len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transaction_df(transaction):\n",
    "    \"\"\"mlxtendのtransaction データに変換する．\n",
    "\n",
    "    Args:\n",
    "        transaction (List[str]): トランザクション\n",
    "\n",
    "    Returns:\n",
    "        pd.Data: データ\n",
    "    \"\"\"\n",
    "    te = TransactionEncoder()\n",
    "    te.fit(transaction)\n",
    "    te_ary = te.transform(transaction)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    return df\n",
    "\n",
    "\n",
    "g_df = get_transaction_df([v  for v in g_transaction.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df_freq_items = fpgrowth(g_df, min_support=MIN_SUPPORT, use_colnames=True)\n",
    "g_df_freq_items.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df_rules = association_rules(\n",
    "    g_df_freq_items, metric=\"confidence\", min_threshold=MIN_CONFIDENCE)\n",
    "\n",
    "# itemの数を加える．\n",
    "g_df_rules[\"antecedent_len\"] = g_df_rules[\"antecedents\"].apply(\n",
    "    lambda x: len(x))\n",
    "g_df_rules[\"consequents_len\"] = g_df_rules[\"consequents\"].apply(\n",
    "    lambda x: len(x))\n",
    "# supportが多いruleに並び直す．\n",
    "g_df_rules = g_df_rules.sort_values(\n",
    "    by=\"support\", ascending=False).reset_index(drop=True)\n",
    "print(g_df_rules.shape)\n",
    "g_df_rules.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "def select_rules(df,  n_ante=1, n_cons=1):\n",
    "    \"\"\"transaction ruleの図示をする．\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): データ    \n",
    "        n_ante (int, optional): size of 前提部. Defaults to 1.\n",
    "        n_cons (int, optional): size of 帰結部. Defaults to 1.\n",
    "    \n",
    "    Returns:\n",
    "        df (pd.DataFrame): データ\n",
    "    \"\"\"\n",
    "    _df = df.copy().reset_index(drop=True)\n",
    "    edgelist = []\n",
    "    for ante, cons in zip(_df[\"antecedents\"], _df[\"consequents\"]):\n",
    "        ante = list(ante)\n",
    "        cons = list(cons)\n",
    "        if len(ante) <= n_ante and len(cons)<=n_cons:\n",
    "            for ante1 in list(ante):\n",
    "                for cons1 in list(cons):\n",
    "                    edgelist.append([str(ante1),str(cons1)])\n",
    "    _df = pd.DataFrame(edgelist, columns=[\"antecedents\",\"consequents\"])\n",
    "    return _df\n",
    "\n",
    "def show_rules(df, figsize=(8,5), seed=1, metadata=METADATA):\n",
    "    \"\"\"transaction ruleの図示をする．\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): データ\n",
    "        figsize (tuple, optional): 図のサイズ. Defaults to (10, 10).\n",
    "        seed (int, optional): nx.drawのseed. Defaults to 1.\n",
    "\n",
    "        metadata (dict, optional): 図のデータ. Defaults to METADATA.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    GA = nx.from_pandas_edgelist(df,\n",
    "                                 source='antecedents', target='consequents',\n",
    "                                 create_using=nx.MultiDiGraph())\n",
    "\n",
    "    if True:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        # use an appropriate method\n",
    "        # see also networkx manual\n",
    "        # nx.draw(GA, node_color=\"yellow\", with_labels=True, ax=ax)\n",
    "        # nx.draw(GA, pos=nx.spring_layout(GA, k=2000,iterations=300, seed=seed), node_color=\"yellow\", with_labels=True, ax=ax)\n",
    "        nx.draw(GA, pos=nx.circular_layout(GA), node_color=\"yellow\", with_labels=True, ax=ax)\n",
    "        # nx.draw(GA, pos=nx.shell_layout(GA), node_color=\"yellow\", with_labels=True, ax=ax)\n",
    "        # nx.draw(GA, pos=nx.spiral_layout(GA), node_color=\"yellow\", with_labels=True, ax=ax)\n",
    "        # nx.draw(GA, pos=nx.random_layout(GA, seed=seed), node_color=\"yellow\", with_labels=True, ax=ax)\n",
    "        xlim = ax.get_xlim()\n",
    "        xrange = ax.get_xlim()[1]-ax.get_xlim()[0]\n",
    "        scale_factor = 0.5\n",
    "        xlim = [xlim[0]-xrange*scale_factor,xlim[1]+xrange*scale_factor]\n",
    "        ax.set_xlim(xlim)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        filename = \"_\".join([metadata[\"prefix\"], metadata[\"dataname\"], \n",
    "                             \"nxdraw\", \"circular_layout\", \n",
    "                             \"support\",metadata[\"support\"], \"confidence\", metadata[\"confidence\"],\n",
    "                             \"shape\", str(df.shape[0])])+\".png\"\n",
    "        print(filename)\n",
    "        fig.savefig(os.path.join(metadata[\"outputdir\"], filename))\n",
    "        plt.show()\n",
    "    \n",
    "    filename = \"_\".join([metadata[\"prefix\"], metadata[\"dataname\"], \n",
    "                         \"support\",metadata[\"support\"], \"confidence\", metadata[\"confidence\"],\n",
    "                         \"shape\",str(df.shape[0])])+\".cyjs\"    \n",
    "    with open(filename,\"w\") as f:\n",
    "        import json\n",
    "        f.write( json.dumps(nx.cytoscape_data(GA))  )\n",
    "    print(filename)\n",
    "    \n",
    "    return GA\n",
    "\n",
    "\n",
    "# g_df_tmp = g_df_rules[g_df_rules[\"antecedent_len\"]==2]\n",
    "# g_df_tmp = g_df_rules.iloc[:15, :]\n",
    "# g_df_tmp = g_df_rules.iloc[:30, :]\n",
    "if SELECT15:\n",
    "    g_df_rules_selected = select_rules(g_df_rules.iloc[:15, :])\n",
    "    print(g_df_rules_selected.shape)\n",
    "    GA = show_rules(g_df_rules_selected)\n",
    "else:\n",
    "    g_df_rules_selected = select_rules(g_df_rules, n_ante=2, n_cons=2)\n",
    "    GA = show_rules(g_df_rules_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元素特徴量の読み込み．\n",
    "g_df_atom = pd.read_csv(\"data/atomicprop.csv\", index_col=[0])\n",
    "g_df_atom.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rule(df_atom, ante, cons):\n",
    "    \"\"\"データ似たいして仮定部に対する結論部でmatchするデータの数を得る．\n",
    "\n",
    "    Args:\n",
    "        df_atom (pd.Data): データ\n",
    "        ante (str): 仮定部\n",
    "        cons (str): 結論部\n",
    "    \"\"\"\n",
    "    dfq_antecedents = df_atom.query(ante)\n",
    "    dfq_consequents = df_atom.query(\"{} and {}\".format(ante, cons))\n",
    "    print(\"confidence {}/{}={}\".format(dfq_consequents.shape[0],dfq_antecedents.shape[0],\n",
    "          dfq_consequents.shape[0]/dfq_antecedents.shape[0]))\n",
    "\n",
    "\n",
    "g_ante = \"log10_electrical_resistivity<-6.90\"\n",
    "g_cons = \"log10_thermal_conductivity>1.73\"\n",
    "query_rule(g_df_atom, g_ante, g_cons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.core.periodic_table import Element\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_xy_symbol(df, x, y, ante=None, cons=None, filename=None):\n",
    "    \"\"\"plot symbols in 2D defined by x and y labels\n",
    "       The points satisfying antecedents are colored in blue.\n",
    "       The points satisfying antecedents and consequents are colored in red.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): data\n",
    "        x (str): x label\n",
    "        y (str): y label\n",
    "        filename (str, optional): filename. Defaults to None.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    df = df.reset_index()\n",
    "    dfq = df[[x, y, \"index\"]].dropna()\n",
    "    for xval, yval, elm in zip(dfq[x].values,\n",
    "                             dfq[y].values,\n",
    "                             dfq[\"index\"].values):\n",
    "        if math.isnan(xval) or math.isnan(yval):\n",
    "            pass\n",
    "        else:\n",
    "            ax.text(xval, yval, elm)\n",
    "    ax.scatter(dfq[x].values,\n",
    "               dfq[y].values, c=\"green\")\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(y)\n",
    "\n",
    "    if ante is not None:\n",
    "        print(\"antecedents={}\".format(ante))\n",
    "        df_ante = df.query(ante)\n",
    "        ax.scatter(df_ante[x].values,\n",
    "                   df_ante[y].values, c=\"blue\")\n",
    "    if ante is not None and cons is not None:\n",
    "        print(\"consequents={}\".format(cons))\n",
    "        df_cons = df.query(\"{} and {}\".format(ante, cons))\n",
    "        ax.scatter(df_cons[x].values,\n",
    "                   df_cons[y].values, c=\"r\")\n",
    "    if filename is not None:\n",
    "        fig.savefig(filename)\n",
    "    # fig.show()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 順序相関関数を同時に出す．\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "def calc_correlation(df_atom,x,y):\n",
    "    \"\"\"\n",
    "    nanを除いてspearman correlationを求める．\n",
    "    \n",
    "    Args:\n",
    "        df_atom (pd.DataFrame): data.\n",
    "        x (str): x column name.\n",
    "        y (str): y column name.\n",
    "    \"\"\"\n",
    "    df = df_atom[[x,y]].dropna()\n",
    "    \n",
    "    psr = pearsonr(df[x].values, df[y].values)\n",
    "    spr  = spearmanr(df[x].values, df[y].values)\n",
    "    print(\"Pearson R\", psr)\n",
    "    print( spr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_xy_symbol(g_df_atom, 'log10_electrical_resistivity', 'log10_thermal_conductivity',\n",
    "               ante=g_ante, cons=g_cons)\n",
    "calc_correlation(g_df_atom, 'log10_electrical_resistivity', 'log10_thermal_conductivity',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ante = \"bulk_modulus>100.00\"\n",
    "g_cons = \"molar_volume<12.29\"\n",
    "plot_xy_symbol(g_df_atom, 'bulk_modulus', 'molar_volume',\n",
    "               ante=g_ante, cons=g_cons)\n",
    "calc_correlation(g_df_atom , 'bulk_modulus', 'molar_volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ante = \"youngs_modulus>105.00\"\n",
    "g_cons = \"molar_volume<12.29\"\n",
    "plot_xy_symbol(g_df_atom, 'youngs_modulus', 'molar_volume',\n",
    "               ante=g_ante, cons=g_cons)\n",
    "calc_correlation(g_df_atom,'youngs_modulus', 'molar_volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ante = \"youngs_modulus>105.00\"\n",
    "g_cons = \"bulk_modulus>100.00\"\n",
    "plot_xy_symbol(g_df_atom, 'youngs_modulus', 'bulk_modulus',\n",
    "               ante=g_ante, cons=g_cons)\n",
    "calc_correlation(g_df_atom,'youngs_modulus', 'bulk_modulus',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ante = \"bulk_modulus>100.00\"\n",
    "g_cons = \"youngs_modulus>105.00\"\n",
    "plot_xy_symbol(g_df_atom, 'bulk_modulus', 'youngs_modulus',\n",
    "               ante=g_ante, cons=g_cons)\n",
    "calc_correlation(g_df_atom,'bulk_modulus', 'youngs_modulus',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
