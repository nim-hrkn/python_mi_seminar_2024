{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946fa8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb744258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pymatgen.core import Element\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import os\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ede72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data():\n",
    "    \"\"\"データ取得\n",
    "\n",
    "    Returns:\n",
    "        tuple containins\n",
    "\n",
    "        - pd.DataFrame: データ．\n",
    "        - list[str]: 元素名リスト．\n",
    "        - list[str]: 目的変数名リスト．\n",
    "        - list[str]: メタカラム名リスト．\n",
    "        - int: 目的へs縫うの分割数．\n",
    "    \"\"\"\n",
    "    import json\n",
    "    ROOT = \"..\"\n",
    "    filepath = os.path.join(f\"data/hea4_phys_condition.json\")\n",
    "    with open(filepath, \"r\") as f:\n",
    "        cond = json.load(f)\n",
    "    ndiv = cond[\"NDIV\"] # digitizeする分割数．\n",
    "    print(\"ndiv\",ndiv)\n",
    "\n",
    "    # 加工済みデータの読み込み\n",
    "    element_labels = []\n",
    "    for i in range(4):\n",
    "        element_labels.append(\"element{}\".format(i+1))\n",
    "    target_names = ['M', 'TC', 'R', ]\n",
    "    meta_names = ['heakey', ]\n",
    "    filepath = \"data/hea4_phys.csv\"\n",
    "    dfraw = pd.read_csv(filepath)\n",
    "    return dfraw, element_labels, target_names, meta_names, ndiv\n",
    "\n",
    "\n",
    "g_dfraw, g_element_labels, g_target_names, g_meta_names, g_ndiv = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA = {\"prefix\": \"image_executed\", \"dataname\": \"hea4_phys_condition\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_dfraw.shape,g_dfraw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed76287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "def apply_regression(df, descriptor_names, target_name,\n",
    "                    labelfontsize=15, tickfontsize=15):\n",
    "    \"\"\"apply fit and predict \n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): data.\n",
    "        descriptor_names (list[str]): 説明変数カラム名リスト．\n",
    "        target_naem (str): 目的変数カラム名．\n",
    "        labelfontsize (int, optional): label font size. Defaults to 15.\n",
    "        tickfontsize (int, optional): ticks font size. Defaults to 15.\n",
    "    \"\"\"\n",
    "    X = df[descriptor_names].values\n",
    "    y = df[target_name].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n",
    "    reg = RandomForestRegressor()\n",
    "    reg.fit(X_train, y_train)\n",
    "    yp_train = reg.predict(X_train)\n",
    "    yp_test = reg.predict(X_test)\n",
    "    r2_train = r2_score(y_train, yp_train)\n",
    "    r2_test = r2_score(y_test,yp_test)\n",
    "    print(\"R2\",r2_train, r2_test)\n",
    "    \n",
    "    if True:\n",
    "        ylim = (y.min(), y.max())\n",
    "        fig, ax = plt.subplots(figsize=(5,5))\n",
    "        ax.scatter(y_test,yp_test, s=1, alpha=0.1)\n",
    "        ax.set_xlim(ylim)\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_xlabel(\"$y_{obs}^{test}$\", fontsize=labelfontsize)\n",
    "        ax.set_ylabel(\"$y_{pred}^{test}$\", fontsize=labelfontsize)\n",
    "        ax.plot(ylim,ylim, \"--\", c=\"red\")\n",
    "        ax.tick_params(axis = 'x', labelsize =tickfontsize)\n",
    "        ax.tick_params(axis = 'y', labelsize =tickfontsize)    \n",
    "        filename = \"itemset_R_group_row_randomforest.pdf\"\n",
    "        print(filename)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(\"image_executed\",filename))\n",
    "        plt.show()\n",
    "        \n",
    "apply_regression(g_dfraw, ['group_mean', 'group_std', 'row_mean', 'row_std'], \"R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f34cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフ図示関数を定義しておく\n",
    "from typing import List\n",
    "\n",
    "def show_rules(df: pd.DataFrame, show_fig = True, filename=None, figsize=(5, 5)):\n",
    "    \"\"\"ruleの図示を行う．\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): データ．\n",
    "        show_fig (bool): show image or not. Defaults to True.\n",
    "        filename (str): filename to output. Defaults to None.\n",
    "        figsize (tuple(float, float), optional): 図のサイズ. Defaults to (5, 5).\n",
    "    \"\"\"\n",
    "    _df = df.copy()\n",
    "    # antecedentsとconsequentsはfrozen setという形式で入っている．\n",
    "    # frozen setだと図示した時に見にくいのでフォーマットの変更を行う．\n",
    "    if False:\n",
    "        # これは１要素の場合しか機能しない．\n",
    "        _df[\"antecedents\"] = _df[\"antecedents\"].apply(lambda x: next(iter(x)))\n",
    "        _df[\"consequents\"] = _df[\"consequents\"].apply(lambda x: next(iter(x)))\n",
    "    else:\n",
    "        edgelist = []\n",
    "        for ante, cons in zip(_df[\"antecedents\"], _df[\"consequents\"]):\n",
    "            ante = list(ante)\n",
    "            cons = list(cons)\n",
    "            for ante1 in list(ante):\n",
    "                for cons1 in list(cons):\n",
    "                    edgelist.append([str(ante1),str(cons1)])\n",
    "        _df = pd.DataFrame(edgelist, columns=[\"antecedents\",\"consequents\"])\n",
    "\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    GA = nx.from_pandas_edgelist(_df,\n",
    "                                 source='antecedents', target='consequents',\n",
    "                                 create_using=nx.MultiDiGraph())\n",
    "    if show_fig:\n",
    "        plt.figure(figsize=figsize)\n",
    "        nx.draw(GA, node_color=\"yellow\", edge_color=\"lightblue\",\n",
    "                arrowsize=20, connectionstyle=\"arc3,rad=0.1\",\n",
    "                font_color=\"red\", with_labels=True)\n",
    "        # plt.tight_layout() はincompatibleだと言われるのでmarginで制御する．\n",
    "        plt.margins(0.3)\n",
    "        if filename is not None:\n",
    "            print(filename)\n",
    "            plt.savefig(filename)\n",
    "        plt.show()\n",
    "        \n",
    "    return GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbdd653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_transaction(df, element_labels,\n",
    "                           feature_id_labels=[\"M_id\", \"TC_id\", \"R_id\",\n",
    "                                              \"group_mean_id\", \"group_std_id\",\n",
    "                                              \"row_mean_id\", \"row_std_id\",\n",
    "                                              'n_group3', 'n_group4', 'n_group5', 'n_group6', 'n_group7',\n",
    "                                              'n_group8', 'n_group9', 'n_group10', 'n_group11', 'n_group12',\n",
    "                                              'n_group13', 'n_group14', 'n_group15',\n",
    "                                              ]):\n",
    "    \"\"\"transactionへの変換．\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): data.\n",
    "        element_labels (list[str])): 元素名リスト\n",
    "        feature_id_labels (list[str]), optional): itemとして使用するカラム名リスト. Defaults to [\"M_id\", \"TC_id\", \"R_id\", \"group_mean_id\", \"group_std_id\", \"row_mean_id\", \"row_std_id\", 'n_group3', 'n_group4', 'n_group5', 'n_group6', 'n_group7', 'n_group8', 'n_group9', 'n_group10', 'n_group11', 'n_group12', 'n_group13', 'n_group14', 'n_group15', ].\n",
    "\n",
    "    Returns:\n",
    "        list: transaction\n",
    "    \"\"\"\n",
    "\n",
    "    discretevalues = {}\n",
    "\n",
    "    for idname in element_labels:\n",
    "        discretevalues[idname] = df[idname].values.tolist()\n",
    "\n",
    "    for idname in feature_id_labels:\n",
    "        value_list = []\n",
    "        for value in df[idname].values.tolist():\n",
    "            if idname == \"R_id\":\n",
    "                valueid = \"{}=={}\".format(idname, value)\n",
    "            elif idname in [\"M_id\", \"TC_id\"]:\n",
    "                if value > 1:\n",
    "                    valueid = \"{}=={}\".format(idname, value)\n",
    "                else:\n",
    "                    valueid = \"\"  # ignore M and TC\n",
    "            elif idname.startswith(\"group\") or idname.startswith(\"row\"):\n",
    "                if value > 0:\n",
    "                    valueid = \"{}=={}\".format(idname, value)\n",
    "                else:\n",
    "                    valueid = \"\"\n",
    "            elif idname.startswith(\"n_\"):\n",
    "                if value > 1:\n",
    "                    valueid = \"{}=={}\".format(idname, value)\n",
    "                else:\n",
    "                    valueid = \"\"\n",
    "            else:\n",
    "                valueid = \"{}=={}\".format(idname, value)\n",
    "            value_list.append(valueid)\n",
    "        discretevalues[idname] = value_list\n",
    "\n",
    "    df_discrete = pd.DataFrame(discretevalues)\n",
    "\n",
    "    transaction = []\n",
    "    for values_raw in df_discrete.values:\n",
    "        values_raw = values_raw.tolist()\n",
    "        values = list(filter(None, values_raw))  # listから””を除く．\n",
    "        transaction.append(values)\n",
    "\n",
    "    return transaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rule(dfraw, element_labels, ndiv, min_support=0.3, min_threshold=0.8,\n",
    "             n_antecedent=1, n_consequents=1):\n",
    "    \"\"\"rule miningを行う．\n",
    "\n",
    "    Args:\n",
    "        dfraw (pd.DataFrame): データ．\n",
    "        element_labels (list[str])): itemとして変換する要素．\n",
    "        ndiv (int): 要素がintやfloatの型の場合のitemの分割数．\n",
    "        min_support (float, optional): supportの最小値. Defaults to 0.3.\n",
    "        min_threshold (float, optional): thresholdの最小値. Defaults to 0.8.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: データ．\n",
    "    \"\"\"\n",
    "    df_rules_list = []\n",
    "    for i in range(ndiv):\n",
    "        target_condition = \"R_id=={}\".format(i+1)\n",
    "        # 「多数」に結果が引きずられる．\n",
    "        # 制限しないとsupportも見るのでR_idの最も大きなpeakの情報が主として出てくる．\n",
    "        dfq = dfraw.query(target_condition).reset_index(drop=True)\n",
    "        transaction = convert_to_transaction(dfq, element_labels,)\n",
    "\n",
    "        te = TransactionEncoder()\n",
    "        te.fit(transaction)\n",
    "        te_ary = te.fit(transaction).transform(transaction)\n",
    "        df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "        df_freq_items = apriori(\n",
    "            df, min_support=min_support, max_len=10000, use_colnames=True, verbose=1)\n",
    "        df_freq_items.sort_values(by=\"support\", ascending=False)\n",
    "        df_rules = association_rules(df_freq_items, metric=\"confidence\",\n",
    "                                     min_threshold=min_threshold)\n",
    "        df_rules = df_rules.sort_values(\n",
    "            by=\"support\", ascending=False).reset_index(drop=True)\n",
    "        # itemの数を加えて制限する．\n",
    "        df_rules[\"antecedent_len\"] = df_rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "        df_rules[\"consequents_len\"] = df_rules[\"consequents\"].apply(lambda x: len(x))\n",
    "        _df_rules = df_rules.query(f'antecedent_len<={n_antecedent} and consequents_len<={n_consequents}').reset_index(drop=True)\n",
    "        display(_df_rules)\n",
    "        df_rules_list.append(_df_rules.copy())\n",
    "        # 可視化する．\n",
    "        GA = show_rules(_df_rules, filename=os.path.join(\"image_executed/target_{}.png\".format(i)), figsize=(5, 5))\n",
    "    return df_rules_list\n",
    "\n",
    "g_df_rules_list = make_rule(g_dfraw, g_element_labels, g_ndiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2103427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_cytoscape(df, comment=\"targetid\", metadata=METADATA):\n",
    "    \"\"\"output cytoscape input\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): data.\n",
    "        comment (str): comment. Defaults to \"hea4_R\".\n",
    "        metadata (dict): data for display. Defaults to METADATA.\n",
    "    \"\"\"\n",
    "    df = pd.concat(df)\n",
    "    df[\"antecedents\"] = df[\"antecedents\"].apply(lambda x: next(iter(x)))\n",
    "    df[\"consequents\"] = df[\"consequents\"].apply(lambda x: next(iter(x)))\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    GA = nx.from_pandas_edgelist(df,\n",
    "                                 source='antecedents', target='consequents',\n",
    "                                 create_using=nx.MultiDiGraph())\n",
    "    filename = \"_\".join([ metadata[\"dataname\"], \n",
    "                         comment])+\".cyjs\"   \n",
    "    with open(filename,\"w\") as f:\n",
    "        import json\n",
    "        f.write( json.dumps(nx.cytoscape_data(GA))  )\n",
    "    print(filename)\n",
    "output_cytoscape(g_df_rules_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1166e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_support(dfraw, sentense, elm):\n",
    "    \"\"\"元データからsupportの計算を行う．\n",
    "\n",
    "    Args:\n",
    "        dfraw (pd.DataFrame): データ．\n",
    "        sentense (str): query文．\n",
    "        elm (str): elementsカラムに含まれる元素名．\n",
    "    \"\"\"\n",
    "    dfq = dfraw.query(sentense)\n",
    "    print(dfq.shape)\n",
    "    dfq2 = dfq[dfq[\"elements\"].str.contains(\",{},\".format(elm))]\n",
    "    print(dfq2.shape)\n",
    "    print(\"support=\", dfq2.shape[0]/dfq.shape[0])\n",
    "\n",
    "\n",
    "make_support(g_dfraw, \"R_id==10\", \"Sc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b82102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全元素名を得る．\n",
    "def get_all_elm(dfraw):\n",
    "    \"\"\"全元素を得る．\n",
    "\n",
    "    Args:\n",
    "        dfraw (pd.DataFrame):データ．\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: unique元素名リスト\n",
    "    \"\"\"\n",
    "    elm1 = dfraw[\"element1\"].values\n",
    "    elm2 = dfraw[\"element2\"].values\n",
    "    elm3 = dfraw[\"element3\"].values\n",
    "    elm4 = dfraw[\"element4\"].values\n",
    "    uique_elms = np.unique(np.hstack([elm1, elm2, elm3, elm4]))\n",
    "    return uique_elms\n",
    "\n",
    "\n",
    "g_uique_elms = get_all_elm(g_dfraw)\n",
    "print(g_uique_elms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57531132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def plot_selected_hist(df, elements, ndiv, label=\"R_id\", filename=None,\n",
    "                      tickfontsize=15, labelfontsize=15, legendfontsize=15):\n",
    "    \"\"\"elementsを含むlabelカラムのhistogramを示す．\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): データ．\n",
    "        elements (list[str]): 元素名リスト．\n",
    "        ndiv (int): labelカラムの値の分割数．\n",
    "        label (str, optional): 物理量のカラム. Defaults to \"R_id\".\n",
    "        filename (str, optional): image filename. Defaults to None.\n",
    "        tickfontsize (int, optional): ticks font size. Defaults to 15.\n",
    "        labelfontsize (int, optional): label font size. Defaults to 15.\n",
    "        legendfontsize (int, optional): legend font size. Defaults to 15.\n",
    "    \"\"\"\n",
    "    dfselect = df.copy()\n",
    "    for elm in elements:\n",
    "        dfselect = dfselect[dfselect[\"elements\"].str.contains(elm)]\n",
    "\n",
    "    # Rのhistogramを生成して規格化\n",
    "    Rall = df[label].values\n",
    "    counter = collections.Counter(Rall)\n",
    "    hist_Rall = []\n",
    "    for i in range(ndiv):\n",
    "        hist_Rall.append(counter[i])\n",
    "    n_sum = np.sum(hist_Rall)\n",
    "    hist_Rall = hist_Rall/n_sum\n",
    "\n",
    "    # dfselect[\"R\"]のhistogramを生成して規格化\n",
    "    Rselect = dfselect[label].values\n",
    "    counter = collections.Counter(Rselect)\n",
    "    hist_Rselect = []\n",
    "    for i in range(ndiv):\n",
    "        hist_Rselect.append(counter[i])\n",
    "    n_sum = np.sum(hist_Rselect)\n",
    "    hist_Rselect = hist_Rselect/n_sum\n",
    "\n",
    "    # 可視化\n",
    "    fig, ax = plt.subplots()\n",
    "    width = 1\n",
    "    center = list(range(1, ndiv+1))\n",
    "    ax.bar(center, hist_Rall, width=width,\n",
    "           alpha=0.5,  align='center', label=\"all\")\n",
    "    ax.bar(center, hist_Rselect, width=width, alpha=0.5,\n",
    "           align='center', label=str(elements))\n",
    "    ax.set_xlabel(label, fontsize=labelfontsize)\n",
    "    ax.set_ylabel(\"normalized occurrence\", fontsize=labelfontsize)\n",
    "    ax.legend(fontsize=legendfontsize)\n",
    "    ax.tick_params(axis = 'x', labelsize =tickfontsize)\n",
    "    ax.tick_params(axis = 'y', labelsize =tickfontsize)    \n",
    "    fig.tight_layout()\n",
    "    if filename is not None:\n",
    "        fig.savefig(filename)\n",
    "        print(\"save to\", filename)\n",
    "    plt.show()\n",
    "\n",
    "for elm in [\"Sc\", \"In\",\"Cd\"]:\n",
    "    g_filename = \"image_executed/R_distrib_{}.pdf\".format(\"_\".join([elm]))\n",
    "    plot_selected_hist(g_dfraw, [elm], g_ndiv,\n",
    "                      filename=g_filename\n",
    "                      )\n",
    "\n",
    "# 分布が偏っている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "\n",
    "def calc_tpvalues(df,  elms, ncombi=1, name=\"R\", ):\n",
    "    \"\"\"t-valueの計算\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): データ．\n",
    "        elms (list[str]): 元素名リスト．\n",
    "        ncombi (int, optional): 元素組み合わせ数. Defaults to 1.\n",
    "        name (str, optional): 対象カラム名. Defaults to \"R\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: データ．\n",
    "    \"\"\"\n",
    "    Rall = df[name].values\n",
    "    tplist = []\n",
    "    comblist = list(combinations(elms, ncombi))\n",
    "\n",
    "    pbar = ProgressBar(max_value=len(comblist))\n",
    "\n",
    "    for i, elm2 in enumerate(comblist):\n",
    "        if i % 5 == 0:\n",
    "            pbar.update(i+1)\n",
    "        dfs = df\n",
    "        for elm1 in elm2:\n",
    "            dfs = dfs[dfs[\"elements\"].str.contains(\",\"+elm1+\",\")]\n",
    "        Rselect = dfs[name].values\n",
    "\n",
    "        if True:\n",
    "            # 今の場合は母集団は分かっているが，\n",
    "            # ランダム化法で母集団からランダムに取る．\n",
    "            # 全部使っても同じ．\n",
    "            population = list(range(Rall.shape[0]))\n",
    "            id_ = np.array(random.sample(population, Rselect.shape[0]))\n",
    "            Rrand = df.loc[id_, name]\n",
    "        else:\n",
    "            Rrand = Rall\n",
    "\n",
    "        t, p = ttest_ind(Rrand, Rselect)\n",
    "        tplist.append([elm2, t, p])\n",
    "    df_tp = pd.DataFrame(tplist, columns=[\"elmements\", \"tvalue\", \"pvalue\"])\n",
    "    df_tp.sort_values(by=\"tvalue\")\n",
    "    return df_tp.sort_values(by=\"tvalue\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "g_df_tp1 = calc_tpvalues(g_dfraw,  g_uique_elms, ncombi=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g_df_tp1.head())\n",
    "display(g_df_tp1.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b79908",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_selected_hist(g_dfraw, [\"Sc\"], g_ndiv, )\n",
    "plot_selected_hist(g_dfraw, [\"Rh\"], g_ndiv,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d434fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df_tp2 = calc_tpvalues(g_dfraw,  g_uique_elms, ncombi=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b002935",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g_df_tp2.head(15))\n",
    "display(g_df_tp2.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87227b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_filename = \"image_executed/R_distrib_{}.pdf\".format(\"_\".join([\"In\", \"Sc\"]))\n",
    "plot_selected_hist(g_dfraw, [\"In\", \"Sc\"], g_ndiv, filename=g_filename)\n",
    "g_filename = \"image_executed/R_distrib_{}.pdf\".format(\"_\".join([\"Ge\", \"Si\"]))\n",
    "plot_selected_hist(g_dfraw, [\"Ge\", \"Si\"], g_ndiv, filename=g_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d35b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dfraw.plot.scatter(x=\"group_std\", y=\"R\", s=1)\n",
    "plt.show()\n",
    "\n",
    "g_dfraw.plot.scatter(x=\"group_mean\", y=\"R\", s=1)\n",
    "plt.show()\n",
    "\n",
    "g_dfraw.plot.scatter(x=\"group_std\", y=\"group_mean\", s=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6f542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "631e33aa572fafc0a3f1363c26f0ce938c74d1e4cffe53590bab1ad626e536d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
