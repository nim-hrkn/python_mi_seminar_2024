{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "必須ではありませんが、アニメーション作成にpillowを用います。\n",
    "Anacondaではインストールされているはずですが、\n",
    "condaを用いたインストール方法についてはこちらをご参照ください。\n",
    "https://anaconda.org/anaconda/pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor, kernels\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import IPython\n",
    "\n",
    "# warning表示を消しておく\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NAME = \"Carbon8\" # \"Carbon\"は炭素結晶構造を用いる。下のget_reordered_data()で定義した他のデータも取得できる。\n",
    "ACQ_FUNC = \"UCB\" # UCB or TS\n",
    "\n",
    "OPTIMIZE = True  # RBFカーネルのガウス過程回帰でカーネルのoptmizeを行うか。\n",
    "LENGTH_SCALE = 2 # RBFカーネルの長さスケール初期値\n",
    "\n",
    "PLOTIT = True # 結果の可視化を行う。\n",
    "MAXITERATION = 50 # ベイズ最適化最大繰り返し回数\n",
    "NSELECT_INITIAL = 8 # 初期訓練データ選択用\n",
    "RAND_SEED_INITIAL = 0 # 初期訓練データ選択用乱数SEED\n",
    "\n",
    "# 獲得関数のパラメタの違いを吸収するための変数\n",
    "# そしてイメージファイル名のパラメタも入れておく。\n",
    "METADATA = {\"outputdir\": \"image_executed\", \"prefix\": \"BayesianOpt_materilals\", \n",
    "              \"dataname\": DATA_NAME, \"acq\": ACQ_FUNC, \"xlabel\": \"index\",\n",
    "              \"rand_seed_ts\": 0, \"v\": 0.3, \"xi\": 0.1}\n",
    "# 獲得関数のパラメタ\n",
    "# v = 0.3 # for UCB\n",
    "# xi = 0.1 # for EI and PI\n",
    "# rand_seed_ts = 0　 # TSのための乱数SEED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私のPython環境でcarbonに対して予め実行した結果を書いておきます。\n",
    "ITERはindex=0が見つかるまでの回数を示します。各自試してみてください。\n",
    "\n",
    "| ACQ | NSELCT_INITIAL |RAND_SEED_INITIAL | ITER |\n",
    "|---|---|---|---|\n",
    "| UCB | 5 | 0 | 8 |\n",
    "| UCB | 5 | 1 | 11 |\n",
    "| UCB | 5 | 2 | 5 |\n",
    "| UCB | 8 | 0 | 21 |\n",
    "| UCB | 8 | 1 | 13 |\n",
    "| UCB | 8 | 2 | 18 |\n",
    "| UCB | 10 | 0 | 25 |\n",
    "| UCB | 10 | 1 | 6 |\n",
    "| UCB | 10 |2 | 18 |\n",
    "| TS | 5 | 0 | 5 |\n",
    "| TS | 5 | 1 | 12 |\n",
    "| TS | 5 | 1 | 10 |\n",
    "| TS | 8 | 0 | 20 |\n",
    "| TS | 8 | 1 |  23 |\n",
    "| TS | 8 | 2 | 14  |\n",
    "| TS | 10 | 0 | 24 |\n",
    "| TS | 10| 1 | 20 |\n",
    "| TS | 10 | 2 | 29 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reordered_data(sample):\n",
    "    \"\"\"データ取得.\n",
    "\n",
    "    sample は\"Carbon\", \"ReCo\", \"ZB_WZ_all\", \"ZB_WZ_3\"を取れる．\n",
    "\n",
    "    Args:\n",
    "        sample (str): データ名\n",
    "\n",
    "    Returns:\n",
    "        tuples containing\n",
    "\n",
    "        - pd.DataFrame: データ\n",
    "        - list[str]: 説明変数名リスト\n",
    "        - str: 目的変数名\n",
    "    \"\"\"\n",
    "    import get_data\n",
    "    \n",
    "    if sample == \"Carbon8\":\n",
    "        df, descriptor_names, target_name = get_data.load('Carbon8_minusE')\n",
    "        df = df.sort_values(\n",
    "            by=target_name, ascending=False).reset_index(drop=True)\n",
    "    elif sample == \"ReCo\":\n",
    "        df, descriptor_names, target_name = get_data.load('Carbon8_minusE')\n",
    "        mata_labels = ['name', 'polytyp', 'ref',\n",
    "                       'author', 'link', 'comment', 'polytyp2']\n",
    "        df = df.sort_values(\n",
    "            by=target_name, ascending=False).reset_index(drop=True)\n",
    "    elif sample == \"ZB_WZ_all\":\n",
    "        df, descriptor_names, target_name = get_data.load('ZB_WZ_all')\n",
    "        df[target_name] = - df[target_name]  # 最大値は離れているので最小値にする．\n",
    "        df = df.sort_values(\n",
    "            by=target_name, ascending=False).reset_index(drop=True)\n",
    "    elif sample == \"ZB_WZ_3\":\n",
    "        df, descriptor_names, target_name = get_data.load('ZB_WZ_3')\n",
    "        df[target_name] = - df[target_name]  # 最大値は離れているので最小値にする．\n",
    "        df = df.sort_values(\n",
    "            by=target_name, ascending=False).reset_index(drop=True)\n",
    "    else:\n",
    "        raise RuntimeError(f'unknonw data_name={sample}')\n",
    "    print(\"df.shape\",df.shape)\n",
    "    return df, descriptor_names, target_name\n",
    "\n",
    "\n",
    "g_df, g_descriptor_names, g_target_name = get_reordered_data(DATA_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_NAME == \"Carbon8\":\n",
    "    \n",
    "    display(g_df[[\"key\", \"minus_energy\", \"polytype\"]][:10])\n",
    "    # 炭素系の場合は一部データにpolytypeが入っている。\n",
    "    # 論文の値を使えないので計算し直している。\n",
    "    # 計算精度が悪いので、graphiteが最もエネルギーが低くなっていない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_break_condition(train):\n",
    "    \"\"\"evaluate the conditon to break the loop\n",
    "\n",
    "    Args:\n",
    "        train (list[int]): training index\n",
    "\n",
    "    Returns:\n",
    "        bool: True if train contains 0 or 1\n",
    "    \"\"\"\n",
    "    # io : list of actions\n",
    "    if 0 in train:\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # pairplotの表示\n",
    "    g_columns = deepcopy(g_descriptor_names)\n",
    "    g_columns.append(g_target_name)\n",
    "    sns.pairplot(g_df[g_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xy(df, descriptor_names, target_name):\n",
    "    \"\"\"\n",
    "        説明変数、目的変数の取得と規格化。\n",
    "    \n",
    "    \"\"\"\n",
    "    Xraw = df.loc[:, descriptor_names].values\n",
    "    yraw = df.loc[:, target_name].values\n",
    "\n",
    "    # standardize\n",
    "    scalerX = StandardScaler()\n",
    "    X = scalerX.fit_transform(Xraw) # 規格化された説明変数\n",
    "    scalery = MinMaxScaler()\n",
    "    y = scalery.fit_transform(yraw.reshape(-1, 1)).reshape(-1) # 可視化の都合で目的変数を[0:1]に直す。\n",
    "    return X, y, scalerX, scalery\n",
    "\n",
    "g_X, g_y, g_scalerX, g_scalery = get_Xy(g_df, g_descriptor_names, g_target_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大値を探す問題設定としている。\n",
    "\n",
    "# インデックス vs 目的変数の可視化\n",
    "# 炭素結晶構造の場合は目的変数がminus energyなのでg_y最大がenergy最小の構造を示す。\n",
    "if PLOTIT:\n",
    "    plt.plot(g_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOTIT:\n",
    "    plt.plot(g_X) # インデックス vs Xの可視化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image_text/150_34.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BO_misc import plot_GPR # 表示用の補助関数\n",
    "from scipy.stats import norm\n",
    "\n",
    "def search_candidate_UCB(it, train, X, y, reg, param, plot=True):\n",
    "    \"\"\"search next action in the UCB method\n",
    "\n",
    "    Args:\n",
    "        it (int): the number of iteration\n",
    "        train (np.array): the index of training data\n",
    "        X (np.array): descriptor\n",
    "        y (np.array): target values\n",
    "        reg (regressor): regressor\n",
    "        param (dict): parameter of UCB\n",
    "        plot (bool): True if show image\n",
    "\n",
    "    Returns:\n",
    "        int: next action\n",
    "    \"\"\"\n",
    "    # GPR training data setの作成\n",
    "    Xtrain = X[train]\n",
    "    ytrain = y[train]\n",
    "    reg.fit(Xtrain, ytrain)\n",
    "    print(\"kernel=\", reg.kernel_)\n",
    "    yp_mean, yp_std = reg.predict(X, return_std=True)\n",
    "    v = param[\"v\"]\n",
    "    acq = yp_mean + yp_std*np.sqrt(v*it)\n",
    "    io = np.argsort(acq)[::-1]\n",
    "    if io[0] in train:\n",
    "        # train listに無い最も小さいindexを探す\n",
    "        print(\"search the other best candidate\")\n",
    "        for ia1 in io:\n",
    "            if ia1 not in train:\n",
    "                ia = ia1\n",
    "                break\n",
    "    else:\n",
    "        ia = io[0]\n",
    "    if plot:\n",
    "        idxall = list(range(y.shape[0]))\n",
    "        plot_GPR(idxall, y, train, ytrain, yp_mean, yp_std, acq, it, ia=ia, metadata=METADATA)\n",
    "    return ia\n",
    "\n",
    "\n",
    "def search_candidate_TS(it, train, X, y, reg, param, plot=True):\n",
    "    \"\"\"search next action in the TS method\n",
    "\n",
    "    Args:\n",
    "        it (int): the number of iteration\n",
    "        train (np.array): the index of training data\n",
    "        X (np.array): descriptor\n",
    "        y (np.array): target values\n",
    "        reg (regressor): regressor\n",
    "        param (dict): TS parameter\n",
    "        plot (bool): True if showing image\n",
    "\n",
    "    Returns:\n",
    "        int: next action\n",
    "    \"\"\"\n",
    "    rand_seed_ts = param[\"rand_seed_ts\"]\n",
    "    # GPR training data setの作成\n",
    "    Xtrain = X[train]\n",
    "    ytrain = y[train]\n",
    "    reg.fit(Xtrain, ytrain)\n",
    "    print(\"kernel=\", reg.kernel_)\n",
    "    y_mean, y_std = reg.predict(X, return_std=True)\n",
    "\n",
    "    # draw a DATA_NAME from GPR, random_stateを指定しないと毎回random_state＝０になる．\n",
    "    acq = reg.sample_y(X, random_state=rand_seed_ts+it)\n",
    "    acq = acq.reshape(-1)\n",
    "    if len(acq.shape) != 1:\n",
    "        print(\"acq.shape\", acq.shape)\n",
    "        raise\n",
    "    io = np.argsort(acq)[::-1]\n",
    "    if io[0] in train:\n",
    "        # train listに無い最も小さいindexを探す\n",
    "        print(io[0], \"in training set, search the other best candidate\")\n",
    "        for ia1 in io:\n",
    "            if ia1 not in train:\n",
    "                ia = ia1\n",
    "                break\n",
    "    else:\n",
    "        ia = io[0]\n",
    "    if plot:\n",
    "        idxall = list(range(y.shape[0]))\n",
    "        plot_GPR(idxall, y, train, ytrain, y_mean, y_std, acq, it, ia=ia, metadata=METADATA)\n",
    "    return ia\n",
    "\n",
    "def search_candidate_EI(it, train, X, y, reg, param, plot=True):\n",
    "    \"\"\"search next action in the EI method\n",
    "\n",
    "    Args:\n",
    "        it (int): the number of iteration\n",
    "        train (np.array): the index of training data\n",
    "        X (np.array): descriptor\n",
    "        y (np.array): target values\n",
    "        reg (regressor): regressor\n",
    "        param (dict): EI parameter\n",
    "        plot (bool): True if showing image\n",
    "\n",
    "    Returns:\n",
    "        int: next action\n",
    "    \"\"\"\n",
    "    # GPR training data setの作成\n",
    "    Xtrain = X[train]\n",
    "    ytrain = y[train]\n",
    "    reg.fit(Xtrain, ytrain)\n",
    "    print(\"kernel=\", reg.kernel_)\n",
    "    y_mean, y_std = reg.predict(X, return_std=True)\n",
    "    fp = np.max(ytrain)\n",
    "    #fp = np.max(y_mean)\n",
    "    xi = param[\"xi\"]\n",
    "    print(\"xi\", xi)\n",
    "    z = (y_mean - fp - xi)/y_std\n",
    "    acq = (y_mean - fp - xi)*norm.cdf(z) + y_std * norm.pdf(z)\n",
    "    if len(acq.shape) != 1:\n",
    "        raise\n",
    "    io = np.argsort(acq)[::-1]\n",
    "    if io[0] in train:\n",
    "        # train listに無い最も小さいindexを探す\n",
    "        print(\"search the other best candidate\")\n",
    "        for ia1 in io:\n",
    "            if ia1 not in train:\n",
    "                ia = ia1\n",
    "                break\n",
    "    else:\n",
    "        ia = io[0]\n",
    "    if plot:\n",
    "        idxall = list(range(y.shape[0]))\n",
    "        plot_GPR(idxall, y, train, ytrain, y_mean, y_std, acq, it, ia=ia, metadata=METADATA)\n",
    "    return ia\n",
    "\n",
    "\n",
    "def search_candidate_PI(it, train, X, y, reg, param, plot=True):\n",
    "    \"\"\"search next action in the PI method\n",
    "\n",
    "    Args:\n",
    "        it (int): the number of iteration\n",
    "        train (np.array): the index of training data\n",
    "        X (np.array): descriptor\n",
    "        y (np.array): target values\n",
    "        reg (regressor): regressor\n",
    "        param (dict): EI parameter\n",
    "        plot (bool): True if showing image\n",
    "\n",
    "    Returns:\n",
    "        int: next action\n",
    "    \"\"\"\n",
    "    # GPR training data setの作成\n",
    "    Xtrain = X[train]\n",
    "    ytrain = y[train]\n",
    "    reg.fit(Xtrain, ytrain)\n",
    "    print(\"kernel=\", reg.kernel_)\n",
    "    y_mean, y_std = reg.predict(X, return_std=True)\n",
    "    fp = np.max(ytrain)\n",
    "    #fp = np.max(y_mean)\n",
    "    xi = param[\"xi\"]\n",
    "    z = (y_mean - fp - xi)/y_std\n",
    "\n",
    "    acq = norm.cdf(z)\n",
    "    acq = acq.reshape(-1)\n",
    "    io = np.argsort(acq)[::-1]\n",
    "    if io[0] in train:\n",
    "        # train listに無い最も小さいindexを探す\n",
    "        print(\"search the other best candidate\")\n",
    "        for ia1 in io:\n",
    "            if ia1 not in train:\n",
    "                ia = ia1\n",
    "                break\n",
    "    else:\n",
    "        ia = io[0]\n",
    "    if plot:\n",
    "        idxall = list(range(y.shape[0]))\n",
    "        plot_GPR(idxall, y, train, ytrain, y_mean, y_std, acq, it, ia=ia, metadata=METADATA)\n",
    "    return ia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_initial_traininigset(nall, nselect=10, seed=1):\n",
    "    \"\"\"select initial actions\n",
    "\n",
    "    [0, nselect)のindexは選択しない．\n",
    "\n",
    "    Args:\n",
    "        nselect (int, optional): the number of actions to select randomly. Defaults to 10.\n",
    "        seed_initial_selection (int, optional): random seed. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of actions\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    train = random.sample(range(nselect, nall), nselect)\n",
    "    print(\"initial action\", train)\n",
    "    return train\n",
    "\n",
    "g_train = select_initial_traininigset(g_X.shape[0], NSELECT_INITIAL, RAND_SEED_INITIAL)\n",
    "# 初期観測済みデータの選択を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(optimize, length_scale=0.5):\n",
    "    \"\"\"ガウス過程回帰モデルを得る．\n",
    "\n",
    "    Args:\n",
    "        optimize (bool): optimizer flag of GaussianProcessRegressor\n",
    "\n",
    "    Returns:\n",
    "        GaussianProcessRegressor: ガウス過程回帰モデル\n",
    "    \"\"\"\n",
    "    if optimize:\n",
    "        kernel = RBF(length_scale=length_scale)\n",
    "        reg = GaussianProcessRegressor(kernel=kernel)\n",
    "        # カーネルパラメタの最適化を行う。\n",
    "    else:\n",
    "        kernel = RBF(length_scale=length_scale)\n",
    "        reg = GaussianProcessRegressor(kernel=kernel, optimizer=None)\n",
    "        # カーネルパラメタの最適化を行わない。\n",
    "    return reg\n",
    "\n",
    "\n",
    "g_reg = make_model(optimize=OPTIMIZE, length_scale=LENGTH_SCALE)\n",
    "# 回帰モデルの定義を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_all(X, y, reg, train, acqfunc, aqsparam, maxiteration, plotit):\n",
    "    \"\"\"最大maxiteration回ベイズ最適化を行う。\n",
    "\n",
    "    acqfuncは\"UCB\", \"TS\", \"PI\", \"EI\"を選択可能．\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): 全てのX\n",
    "        y (np.ndarray): 全てのy\n",
    "        reg (GaussianProcessRegressor): ガウス過程回帰モデル\n",
    "        train (list[int]): 観測済データ（訓練データ）\n",
    "        acqfunc (str): 獲得関数名\n",
    "        aqsparam (dict)): 獲得関数計算時のパラメタ\n",
    "        maxiteration (int): 最大探索回数\n",
    "        plotit (bool): 図示するかどうか．\n",
    "\n",
    "    Raises:\n",
    "        ValueError: _description_\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 観測データリスト\n",
    "    \"\"\"\n",
    "    if acqfunc == \"UCB\":\n",
    "        search_function = search_candidate_UCB\n",
    "    elif acqfunc == \"TS\":\n",
    "        search_function = search_candidate_TS\n",
    "    elif acqfunc == \"PI\":\n",
    "        search_function = search_candidate_PI\n",
    "    elif acqfunc == \"EI\":\n",
    "        search_function = search_candidate_EI\n",
    "    else:\n",
    "        raise ValueError(\"unknown acqfunc={}\".format(acqfunc))\n",
    "            \n",
    "    for _it in range(maxiteration):\n",
    "        print()\n",
    "        print(\"iteration=\", _it+1)\n",
    "        print(\"action=\", train)\n",
    "\n",
    "        _ia = search_function(_it, train, X, y, reg, aqsparam, plot=plotit) \n",
    "        #　獲得関数から次のaction=探索点を得る。\n",
    "        # search_functionでは重複しないように次善点も選択する。\n",
    "        print(\"next action=\", _ia) # 次のaction=探索点を表示する。\n",
    "\n",
    "        train = np.hstack([train, _ia]) # 訓練データに追加する。\n",
    "        if evaluate_break_condition(train):\n",
    "            print(\"found both minima, iteration=\", _it+1)\n",
    "            break\n",
    "\n",
    "    print(\"\\nfinal action\", train)\n",
    "    return train\n",
    "\n",
    "g_train = search_all(g_X, g_y, g_reg, g_train, ACQ_FUNC,\n",
    "                     METADATA, MAXITERATION, PLOTIT)\n",
    "# ベイズ最適化の実行\n",
    "# カーネルパラメタの表示も行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PLOTIT:\n",
    "    # PLOTITでない場合は終了する。\n",
    "    raise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PILがあれば、animation gifを作成、表示する。\n",
    "try:\n",
    "    from PIL import Image\n",
    "    have_PIL = True\n",
    "except ModuleNotFoundError:\n",
    "    have_PIL = False\n",
    "print(have_PIL) # PILライブラリがあるかどうかを表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_acq_animation(filename_acqgif, have_PIL):\n",
    "    if have_PIL:\n",
    "        return IPython.display.Image(filename_acqgif)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "if have_PIL:\n",
    "    from BO_misc import make_acq_animation\n",
    "    filename_acqgif = make_acq_animation(NSELECT_INITIAL, g_train, metadata=METADATA)\n",
    "\n",
    "show_acq_animation(filename_acqgif, have_PIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BO_misc import show_energysurface\n",
    "show_energysurface(g_X, g_y, g_df, metadata=METADATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BO_misc import show_2D_actions\n",
    "show_2D_actions(g_X, g_y, NSELECT_INITIAL, g_train, g_df, DATA_NAME, metadata=METADATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gif_pca_gif(train, nselect, metadata, have_PIL):\n",
    "    if have_PIL:\n",
    "        from BO_misc import make_pca_gif\n",
    "        g_filename_pcagif = make_pca_gif(train, nselect, metadata=metadata)\n",
    "        return IPython.display.Image(g_filename_pcagif)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "show_gif_pca_gif(g_train, NSELECT_INITIAL, METADATA, have_PIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
